{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = \"This pasta is very tasty and afforable\"\n",
    "review2 = \"This pasta is not tasty and is afforable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the vector of all the words in the document \n",
    "total_words = review1.split() + review2.split()\n",
    "unique_words = list(set(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afforable', 'and', 'very', 'tasty', 'pasta', 'This', 'not', 'is']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the 2 reviews into vector \n",
    "vector1 = [0] * len(unique_words)\n",
    "vector2 = [0] * len(unique_words)\n",
    "\n",
    "for word in unique_words:\n",
    "    if word in review1:\n",
    "        vector1[unique_words.index(word)] += 1\n",
    "    if word in review2:\n",
    "        vector2[unique_words.index(word)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 , vector2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These 2 vectors represent the original sentence \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance between the 2 vectors using l1 norm \n",
    "distance = np.linalg.norm(np.array(vector1) - np.array(vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distance between these two vector should be large as they have opposite symentic meaning but the distance between the vectors are very small because BOW calculate euclidean distance based on the number of similar words. This is a limitation of BOW model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
